{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAMPLE GENERATION (BIGRAM LEVEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/Users/shrutijha/Desktop/corpus.txt'\n",
    "from utils import emotion_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_with_emotion(bigram_model, min_size, target_emotion):\n",
    "    while True:\n",
    "        text = ['$']\n",
    "        for _ in range(min_size):  \n",
    "            possible_bigrams = [(text[-1], word) for word in bigram_model.bigram_counts[text[-1]].keys()]\n",
    "            if not possible_bigrams:\n",
    "                break \n",
    "\n",
    "            probabilities = []\n",
    "            for bigram in possible_bigrams:\n",
    "                word1, word2 = bigram\n",
    "                bigram_probability = bigram_model.get_probability(word1, word2)\n",
    "                bigram_emotions = emotion_scores(f\"{word1} {word2}\")  \n",
    "                emotion_score = next((e['score'] for e in bigram_emotions if e['label'] == target_emotion), 0)\n",
    "                adjusted_probability = bigram_probability + emotion_score\n",
    "                probabilities.append((word2, adjusted_probability))\n",
    "\n",
    "            total_prob = sum(prob for _, prob in probabilities)\n",
    "            normalized_probs = [(word, prob / total_prob) for word, prob in probabilities]\n",
    "\n",
    "            next_word = np.random.choice([word for word, _ in normalized_probs], p=[prob for _, prob in normalized_probs])\n",
    "            text.append(next_word)\n",
    "\n",
    "        generated_text = ' '.join(text[1:])  \n",
    "        if len(generated_text.split()) >= min_size:\n",
    "            break\n",
    "\n",
    "    generated_text_emotion_scores = emotion_scores(generated_text)  \n",
    "    return generated_text, generated_text_emotion_scores\n",
    "\n",
    "kn_model = BigramLM.load_model('kn_model.pkl')\n",
    "\n",
    "def write_generated_texts_to_file(bigram_lm, sample_size, target_emotion, num_samples, file_name):\n",
    "    with open(file_name, 'w') as file:\n",
    "        for i in range(num_samples):\n",
    "            generated_text, generated_text_emotion_scores = generate_text_with_emotion(bigram_lm,sample_size, target_emotion)\n",
    "            file.write(f\"{generated_text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sample_size = 8\n",
    "target_emotion = 'anger' \n",
    "file = 'gen_anger2.txt'  \n",
    "write_generated_texts_to_file(kn_model, min_sample_size, target_emotion, 50, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sample_size = 10\n",
    "target_emotion = 'surprise' \n",
    "file = 'gen_surprise2.txt'  \n",
    "write_generated_texts_to_file(kn_model, min_sample_size, target_emotion, 50, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sample_size = 10\n",
    "target_emotion = 'joy' \n",
    "file = 'gen_joy2.txt'  \n",
    "write_generated_texts_to_file(kn_model, min_sample_size, target_emotion, 50, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sample_size = 10\n",
    "target_emotion = 'love' \n",
    "file = 'gen_love2.txt'  \n",
    "write_generated_texts_to_file(kn_model, min_sample_size, target_emotion, 50, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sample_size = 10\n",
    "target_emotion = 'sadness' \n",
    "file = 'gen_sadness2.txt'  \n",
    "write_generated_texts_to_file(kn_model, min_sample_size, target_emotion, 50, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sample_size = 10\n",
    "target_emotion = 'fear' \n",
    "file = 'gen_fear2.txt'  \n",
    "write_generated_texts_to_file(kn_model, min_sample_size, target_emotion, 50, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAMPLE GENERATION (UNIGRAM LEVEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_with_emotion(bigram_model, min_size, target_emotion):\n",
    "    while True:\n",
    "        text = ['$']\n",
    "        for _ in range(min_size):  \n",
    "            possible_words = list(bigram_model.bigram_counts[text[-1]].keys())\n",
    "            if not possible_words:\n",
    "                break  \n",
    "\n",
    "            probabilities = []\n",
    "            for word in possible_words:\n",
    "                word_probability = bigram_model.get_probability(text[-1], word)\n",
    "                word_emotions = emotion_scores(word)\n",
    "                emotion_score = next((e['score'] for e in word_emotions if e['label'] == target_emotion), 0)\n",
    "                adjusted_probability = word_probability + emotion_score\n",
    "                probabilities.append((word, adjusted_probability))\n",
    "\n",
    "            total_prob = sum(prob for _, prob in probabilities)\n",
    "            normalized_probs = [(word, prob / total_prob) for word, prob in probabilities]\n",
    "\n",
    "            next_word = np.random.choice([word for word, _ in normalized_probs], p=[prob for _, prob in normalized_probs])\n",
    "            text.append(next_word)\n",
    "\n",
    "        generated_text = ' '.join(text[1:])  \n",
    "        if len(generated_text.split()) >= min_size:\n",
    "            break\n",
    "\n",
    "    generated_text_emotion_scores = emotion_scores(generated_text)\n",
    "    return generated_text, generated_text_emotion_scores\n",
    "\n",
    "kn_model = BigramLM.load_model('kn_model.pkl')\n",
    "\n",
    "def write_generated_texts_to_file(bigram_lm, sample_size, target_emotion, num_samples, file_name):\n",
    "    with open(file_name, 'w') as file:\n",
    "        for i in range(num_samples):\n",
    "            generated_text, generated_text_emotion_scores = generate_text_with_emotion(bigram_lm,sample_size, target_emotion)\n",
    "            file.write(f\"{generated_text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sample_size = 10\n",
    "target_emotion = 'joy' \n",
    "file = 'gen_joy3.txt'  \n",
    "write_generated_texts_to_file(kn_model, min_sample_size, target_emotion, 50, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sample_size = 10\n",
    "target_emotion = 'love' \n",
    "file = 'gen_love3.txt'  \n",
    "write_generated_texts_to_file(kn_model, min_sample_size, target_emotion, 50, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sample_size = 10\n",
    "target_emotion = 'anger' \n",
    "file = 'gen_anger3.txt'  \n",
    "write_generated_texts_to_file(kn_model, min_sample_size, target_emotion, 50, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sample_size = 10\n",
    "target_emotion = 'surprise' \n",
    "file = 'gen_surprise3.txt'  \n",
    "write_generated_texts_to_file(kn_model, min_sample_size, target_emotion, 50, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sample_size = 10\n",
    "target_emotion = 'fear' \n",
    "file = 'gen_fear3.txt'  \n",
    "write_generated_texts_to_file(kn_model, min_sample_size, target_emotion, 50, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sample_size = 10\n",
    "target_emotion = 'sadness' \n",
    "file = 'gen_sadness3.txt'  \n",
    "write_generated_texts_to_file(kn_model, min_sample_size, target_emotion, 50, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXTRINISIC EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def merge_text_files(file_list, output_file):\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        for fname in file_list:\n",
    "            if os.path.isfile(fname):\n",
    "                with open(fname, 'r') as infile:\n",
    "                    outfile.write(infile.read())\n",
    "            else:\n",
    "                print(f\"File not found: {fname}\")\n",
    "\n",
    "file_list = ['gen_sadness2.txt', 'gen_joy2.txt', 'gen_anger2.txt', 'gen_fear2.txt', 'gen_love2.txt', 'gen_surprise2.txt']\n",
    "output_file = 'merged_file1.txt'\n",
    "merge_text_files(file_list, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6033333333333334\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.60      0.56        50\n",
      "           1       0.40      0.48      0.44        50\n",
      "           2       0.51      0.36      0.42        50\n",
      "           3       0.57      0.48      0.52        50\n",
      "           4       0.71      0.94      0.81        50\n",
      "           5       0.97      0.76      0.85        50\n",
      "\n",
      "    accuracy                           0.60       300\n",
      "   macro avg       0.61      0.60      0.60       300\n",
      "weighted avg       0.61      0.60      0.60       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "def preprocess(text):\n",
    "        ts = []\n",
    "        for t in text:\n",
    "            t = t.replace('.', ' ').replace(',', ' ').replace('?', ' ').replace('!', ' ')\n",
    "            t = t.lower()\n",
    "            ts.append(t)\n",
    "        return ts\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    corpus = file.readlines()\n",
    "\n",
    "with open('merged_file1.txt', 'r') as file:\n",
    "    Test_data = file.readlines()\n",
    "\n",
    "with open('/Users/shrutijha/Desktop/labels.txt', 'r') as file:\n",
    "    labels = file.readlines()\n",
    "\n",
    "\n",
    "label_mapping = {'sadness': 0, 'joy': 1, 'anger': 2, 'fear': 3, 'love': 4, 'surprise': 5}\n",
    "labels = np.array([label_mapping[label.strip()] for label in labels])\n",
    "\n",
    "Train_data = preprocess(corpus)\n",
    "\n",
    "y_test = [0]*50 + [1]*50 + [2]*50 + [3]*50 + [4]*50 + [5]*50\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train = tfidf_vectorizer.fit_transform(Train_data)\n",
    "X_test = tfidf_vectorizer.transform(Test_data)  \n",
    "\n",
    "svc = SVC(kernel='linear')  \n",
    "svc.fit(X_train, labels)\n",
    "\n",
    "y_pred = svc.predict(X_test)\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'C': 1.5, 'kernel': 'linear'}\n",
      "Test accuracy: 0.6166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.64      0.58        50\n",
      "           1       0.45      0.46      0.46        50\n",
      "           2       0.49      0.36      0.41        50\n",
      "           3       0.57      0.52      0.54        50\n",
      "           4       0.71      0.94      0.81        50\n",
      "           5       0.97      0.78      0.87        50\n",
      "\n",
      "    accuracy                           0.62       300\n",
      "   macro avg       0.62      0.62      0.61       300\n",
      "weighted avg       0.62      0.62      0.61       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [0.1, 0.5, 0.75, 1, 1.5, 3, 5, 10], \n",
    "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "grid_search.fit(X_train, labels)\n",
    "\n",
    "print('Best parameters found:', grid_search.best_params_)\n",
    "\n",
    "best_svc = grid_search.best_estimator_\n",
    "test_predictions = best_svc.predict(X_test)\n",
    "print('Test accuracy:', accuracy_score(y_test, test_predictions))\n",
    "print(classification_report(y_test, test_predictions))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4576502f05eb02d3b6de5ab255787e50d09edc468e4e3e2eb125a21834dc8344"
  },
  "kernelspec": {
   "display_name": "Python 3.11.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
